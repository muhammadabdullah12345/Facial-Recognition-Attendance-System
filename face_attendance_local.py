# -*- coding: utf-8 -*-
"""face_attendance_local

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Nx2tmkJmPhVB2rr9H9U3oCdfFe-xOc0
"""

#!/usr/bin/env python3
"""
PURE LOCAL FACE ATTENDANCE SYSTEM
No GitHub, no downloads.
"""

import os
import cv2
import numpy as np
import pandas as pd
import pickle
import time
from datetime import datetime
from deepface import DeepFace

# ================= CONFIG =================
DATASET_FOLDER = "CV Dataset"      # YOUR dataset folder
ATTENDANCE_FILE = "attendance.csv"
EMBEDDINGS_FILE = "face_embeddings.pkl"
CONFIDENCE_THRESHOLD = 0.65
COOLDOWN_SECONDS = 30

# ================= TRAIN ON LOCAL DATA =================
def train_on_local_data():
    """Train ONLY on your local dataset"""
    print(f"[TRAINING] Loading faces from: {DATASET_FOLDER}")

    if not os.path.exists(DATASET_FOLDER):
        print(f"[ERROR] Folder '{DATASET_FOLDER}' not found!")
        print(f"[INFO] Create '{DATASET_FOLDER}' and add face images")
        print(f"       Format: person_name.jpg or person_name/")
        return {}

    known_faces = {}
    image_count = 0

    # Scan dataset folder
    for item in os.listdir(DATASET_FOLDER):
        item_path = os.path.join(DATASET_FOLDER, item)

        # If it's a directory (person folder)
        if os.path.isdir(item_path):
            person_name = item
            for img_file in os.listdir(item_path):
                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    img_path = os.path.join(item_path, img_file)
                    if process_image(img_path, person_name, known_faces):
                        image_count += 1
                        break  # Use first good image per person

        # If it's an image file directly
        elif item.lower().endswith(('.jpg', '.jpeg', '.png')):
            person_name = os.path.splitext(item)[0]
            if process_image(item_path, person_name, known_faces):
                image_count += 1

    print(f"[TRAINING COMPLETE] Learned {len(known_faces)} faces from {image_count} images")

    # Save embeddings for faster startup
    with open(EMBEDDINGS_FILE, 'wb') as f:
        pickle.dump(known_faces, f)

    return known_faces

def process_image(img_path, person_name, known_faces):
    """Extract face embedding from single image"""
    try:
        embedding = DeepFace.represent(
            img_path=img_path,
            model_name='Facenet512',
            detector_backend='retinaface',
            enforce_detection=False
        )
        if embedding:
            known_faces[person_name] = embedding[0]['embedding']
            print(f"  ✓ Learned: {person_name}")
            return True
    except Exception as e:
        print(f"  ✗ {person_name}: {str(e)[:50]}")
    return False

# ================= RECOGNITION =================
def recognize_face(face_img, known_faces):
    """Recognize face against known faces"""
    if not known_faces:
        return "Unknown", 0.0

    try:
        # Save temp image for processing
        temp_path = "temp_face.jpg"
        cv2.imwrite(temp_path, face_img)

        # Get embedding for detected face
        embedding = DeepFace.represent(
            img_path=temp_path,
            model_name='Facenet512',
            detector_backend='retinaface',
            enforce_detection=False
        )

        os.remove(temp_path)

        if not embedding:
            return "Unknown", 0.0

        detected_emb = np.array(embedding[0]['embedding'])
        best_match = "Unknown"
        best_distance = float('inf')

        # Compare with all known faces
        for name, known_emb in known_faces.items():
            known_arr = np.array(known_emb)

            # Cosine similarity
            norm_a = known_arr / (np.linalg.norm(known_arr) + 1e-10)
            norm_b = detected_emb / (np.linalg.norm(detected_emb) + 1e-10)
            similarity = np.dot(norm_a, norm_b)
            distance = 1 - similarity

            if distance < best_distance:
                best_distance = distance
                best_match = name

        confidence = max(0, 1 - best_distance)

        if confidence < CONFIDENCE_THRESHOLD:
            return "Unknown", confidence

        return best_match, confidence

    except Exception:
        return "Unknown", 0.0

# ================= ATTENDANCE LOGGING =================
class AttendanceLogger:
    def __init__(self):
        self.last_detection = {}

    def log_attendance(self, name, confidence):
        """Log attendance with cooldown"""
        current_time = time.time()
        last_time = self.last_detection.get(name, 0)

        if (current_time - last_time) < COOLDOWN_SECONDS:
            return False

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Load or create attendance file
        if os.path.exists(ATTENDANCE_FILE):
            df = pd.read_csv(ATTENDANCE_FILE)
        else:
            df = pd.DataFrame(columns=['Name', 'Time', 'Confidence'])

        # Add new entry
        new_entry = pd.DataFrame({
            'Name': [name],
            'Time': [timestamp],
            'Confidence': [f"{confidence:.3f}"]
        })

        df = pd.concat([df, new_entry], ignore_index=True)
        df.to_csv(ATTENDANCE_FILE, index=False)

        self.last_detection[name] = current_time
        print(f"✓ {name} - {timestamp} ({confidence:.2f})")
        return True

# ================= MAIN SYSTEM =================
def main():
    print("=" * 60)
    print("PURE LOCAL FACE ATTENDANCE")
    print("=" * 60)

    # Step 1: Train on local data
    known_faces = train_on_local_data()

    if not known_faces:
        print("[WARNING] Running in detection-only mode")
        print("[INFO] Add face images to 'CV Dataset' folder")

    # Step 2: Initialize camera
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("[ERROR] Camera not accessible")
        return

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    print(f"[CAMERA] 640x480 | Faces in DB: {len(known_faces)}")
    print("[CONTROLS] Q=Quit | S=Save frame | R=Retrain")
    print("=" * 60)

    # Step 3: Main loop
    attendance_logger = AttendanceLogger()
    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        if frame_count % 3 != 0:  # Skip frames
            continue

        display = frame.copy()

        # Detect faces
        try:
            faces = DeepFace.extract_faces(
                img_path=frame,
                detector_backend='retinaface',
                enforce_detection=False,
                align=False
            )

            for face in faces:
                if 'facial_area' in face:
                    x, y, w, h = face['facial_area'].values()

                    # Skip small faces
                    if w < 40 or h < 40:
                        continue

                    # Extract face region
                    face_region = frame[y:y+h, x:x+w]

                    # Recognize
                    if face_region.size > 0 and known_faces:
                        name, confidence = recognize_face(face_region, known_faces)

                        # Draw results
                        color = (0, 255, 0) if name != "Unknown" else (0, 0, 255)
                        cv2.rectangle(display, (x, y), (x+w, y+h), color, 2)

                        label = f"{name} ({confidence:.2f})"
                        cv2.putText(display, label, (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

                        # Log attendance
                        if name != "Unknown":
                            attendance_logger.log_attendance(name, confidence)
                    else:
                        # Just draw detection box
                        cv2.rectangle(display, (x, y), (x+w, y+h), (255, 200, 0), 2)
                        cv2.putText(display, "Face Detected", (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 0), 2)

        except Exception:
            pass

        # Display info
        cv2.putText(display, f"Faces in DB: {len(known_faces)}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        cv2.putText(display, "LOCAL DATASET MODE", (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        cv2.putText(display, "Press Q to quit", (10, 450),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        cv2.imshow('Local Face Attendance', display)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('r'):
            print("[RETRAINING] Reloading dataset...")
            known_faces = train_on_local_data()
        elif key == ord('s'):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            cv2.imwrite(f"capture_{timestamp}.jpg", frame)
            print(f"[SAVED] capture_{timestamp}.jpg")

    cap.release()
    cv2.destroyAllWindows()
    print(f"\n[COMPLETE] Attendance saved to: {ATTENDANCE_FILE}")
    print(f"          Embeddings saved to: {EMBEDDINGS_FILE}")

# ================= START =================
if __name__ == "__main__":
    main()